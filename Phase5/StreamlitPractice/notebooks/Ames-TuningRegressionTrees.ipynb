{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regression Trees and Model Optimization - Lab\n",
    "\n",
    "## Introduction\n",
    "\n",
    "In this lab, we'll see how to apply regression analysis using CART trees while making use of some hyperparameter tuning to improve our model. \n",
    "\n",
    "## Objectives\n",
    "\n",
    "In this lab you will: \n",
    "\n",
    "- Perform the full process of cleaning data, tuning hyperparameters, creating visualizations, and evaluating decision tree models \n",
    "- Determine the optimal hyperparameters for a decision tree model and evaluate the performance of decision tree models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ames Housing dataset \n",
    "\n",
    "The dataset is available in the file `'ames.csv'`. \n",
    "\n",
    "- Import the dataset and examine its dimensions: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('ggplot')\n",
    "%matplotlib inline\n",
    "\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Ames housing dataset \n",
    "data = pd.read_csv('../data/ames.csv')\n",
    "\n",
    "# Print the dimensions of data\n",
    "print(data.shape)\n",
    "\n",
    "# Check out the info for the dataframe\n",
    "print(data.info())\n",
    "\n",
    "# Show the first 5 rows\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Identify features and target data \n",
    "\n",
    "In this lab, we will use using 3 predictive continuous features:\n",
    "\n",
    "#### Features\n",
    "\n",
    "- `LotArea`: Lot size in square feet\n",
    "- `1stFlrSF`: Size of first floor in square feet\n",
    "- `GrLivArea`: Above grade (ground) living area square feet\n",
    "\n",
    "#### Target\n",
    "\n",
    "- `SalePrice`', the sale price of the home, in dollars"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Create DataFrames for the features and the target variable as shown above \n",
    "- Inspect the contents of both the features and the target variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Features and target data\n",
    "used_cols = ['LotArea', '1stFlrSF', 'GrLivArea']\n",
    "features = data[used_cols]\n",
    "\n",
    "target = data['SalePrice']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "features.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inspect correlations \n",
    "\n",
    "- Use scatter plots to show the correlation between the chosen features and the target variable\n",
    "- Comment on each scatter plot "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here \n",
    "plt.figure(figsize=(20, 5))\n",
    "for i, col in enumerate(features.columns):\n",
    "    plt.subplot(1, 3, i+1)\n",
    "    plt.plot(data[col], target, 'o')\n",
    "    plt.title(col)\n",
    "    plt.xlabel(col)\n",
    "    plt.ylabel('Prices')\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Removing Outliers\n",
    "\n",
    "Will only allow our app to insert specific numbers, so going to reflect these numbers in our training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Features and target data\n",
    "df_comb = features.copy()\n",
    "df_comb['target'] = target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_comb.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_comb.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Determining where we should put our cutoffs:\n",
    "\n",
    "https://stackoverflow.com/questions/23199796/detect-and-exclude-outliers-in-pandas-data-frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_comb[(np.abs(stats.zscore(df_comb)) < 3).all(axis=1)].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bound_vals = [[1300, 40000], [350, 2250], [350, 3000]]\n",
    "\n",
    "col_vals = dict(zip(used_cols, bound_vals))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col, vals in col_vals.items():\n",
    "    df_comb = df_comb.loc[df_comb[col] >= vals[0]]\n",
    "    df_comb = df_comb.loc[df_comb[col] <= vals[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_comb.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = df_comb[used_cols]\n",
    "\n",
    "target = df_comb['target']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create evaluation metrics\n",
    "\n",
    "- Import `r2_score` and `mean_squared_error` from `sklearn.metrics` \n",
    "- Create a function `performance(true, predicted)` to calculate and return both the R-squared score and Root Mean Squared Error (RMSE) for two equal-sized arrays for the given true and predicted values \n",
    "    - Depending on your version of sklearn, in order to get the RMSE score you will need to either set `squared=False` or you will need to take the square root of the output of the `mean_squared_error` function - check out [the documentation](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.mean_squared_error.html) or this helpful and related [StackOverflow post](https://stackoverflow.com/questions/17197492/is-there-a-library-function-for-root-mean-square-error-rmse-in-python)\n",
    "    - The benefit of calculating RMSE instead of the Mean Squared Error (MSE) is that RMSE is in the same units at the target - here, this means that RMSE will be in dollars, calculating how far off in dollars our predictions are away from the actual prices for homes, on average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import metrics\n",
    "\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "\n",
    "# Define the function\n",
    "def performance(y_true, y_predict):\n",
    "    \"\"\" \n",
    "    Calculates and returns the two performance scores between \n",
    "    true and predicted values - first R-Squared, then RMSE\n",
    "    \"\"\"\n",
    "\n",
    "    # Calculate the r2 score between 'y_true' and 'y_predict'\n",
    "    r2 = r2_score(y_true, y_predict)\n",
    "\n",
    "    # Calculate the root mean squared error between 'y_true' and 'y_predict'\n",
    "    rmse = mean_squared_error(y_true, y_predict, squared=False)\n",
    "\n",
    "    # If using an older version of sklearn:\n",
    "    # rmse = np.sqrt(mean_squared_error(y_true, y_predict))\n",
    "\n",
    "    # Return the score\n",
    "    return [r2, rmse]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split the data into training and test sets\n",
    "\n",
    "- Split `features` and `target` datasets into training/test data (80/20) \n",
    "- For reproducibility, use `random_state=42`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split the data into training and test subsets\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    features, target, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grow a vanilla regression tree\n",
    "\n",
    "- Import the `DecisionTreeRegressor` class\n",
    "- Run a baseline model for later comparison using the datasets created above\n",
    "- Generate predictions for test dataset and calculate the performance measures using the function created above \n",
    "- Use `random_state=45` for tree instance\n",
    "- Record your observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import DecisionTreeRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "# Instantiate DecisionTreeRegressor \n",
    "# Set random_state=45\n",
    "regressor = DecisionTreeRegressor(random_state=45)\n",
    "\n",
    "# Fit the model to training data\n",
    "regressor.fit(x_train, y_train)\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred = regressor.predict(x_test)\n",
    "\n",
    "# Calculate performance using the performance() function \n",
    "score = performance(y_test, y_pred)\n",
    "score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter tuning (I)\n",
    "\n",
    "- Find the best tree depth using depth range: 1-30\n",
    "- Run the regressor repeatedly in a `for` loop for each depth value  \n",
    "- Use `random_state=45` for reproducibility\n",
    "- Calculate RMSE and r-squared for each run \n",
    "- Plot both performance measures for all runs \n",
    "- Comment on the output "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here # Identify the optimal tree depth for given data\n",
    "max_depths = np.linspace(1, 30, 30, endpoint=True)\n",
    "mse_results = []\n",
    "r2_results = []\n",
    "\n",
    "for max_depth in max_depths:\n",
    "    regressor = DecisionTreeRegressor(max_depth=max_depth, \n",
    "                                      random_state=45)\n",
    "    regressor.fit(x_train, y_train)\n",
    "    y_pred = regressor.predict(x_test)\n",
    "    score = performance(y_test, y_pred)\n",
    "    r2_results.append(score[0])\n",
    "    mse_results.append(score[1])\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(max_depths, r2_results, 'b', label='R2')\n",
    "plt.xlabel('Tree Depth')\n",
    "plt.ylabel('R-squared')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(max_depths, mse_results, 'r', label='RMSE')\n",
    "plt.xlabel('Tree Depth')\n",
    "plt.ylabel('RMSE')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter tuning (II)\n",
    "\n",
    "- Repeat the above process for `min_samples_split` \n",
    "- Use a range of values from 2-10 for this hyperparameter \n",
    "- Use `random_state=45` for reproducibility\n",
    "- Visualize the output and comment on results as above "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify the optimal minimum split size for given data\n",
    "min_samples_splits = np.arange(2, 21)\n",
    "mse_results = []\n",
    "r2_results = []\n",
    "\n",
    "for min_samples_split in min_samples_splits:\n",
    "    regressor = DecisionTreeRegressor(min_samples_split=int(min_samples_split),\n",
    "                                      random_state=45)\n",
    "    regressor.fit(x_train, y_train)\n",
    "    y_pred = regressor.predict(x_test)\n",
    "    score = performance(y_test, y_pred)\n",
    "    r2_results.append(score[0])\n",
    "    mse_results.append(score[1])\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(min_samples_splits, r2_results, 'b', label='R2')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(min_samples_splits, mse_results, 'r', label='RMSE')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run the *optimized* model \n",
    "\n",
    "- Use the best values for `max_depth` and `min_samples_split` found in previous runs and run an optimized model with these values \n",
    "- Calculate the performance and comment on the output "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regressor = DecisionTreeRegressor(min_samples_split=15, max_depth=5, random_state=45)\n",
    "regressor.fit(x_train, y_train)\n",
    "y_pred = regressor.predict(x_test)\n",
    "score = performance(y_test, y_pred)\n",
    "score[0], score[1], regressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Level up (Optional)\n",
    "\n",
    "- How about bringing in some more features from the original dataset which may be good predictors?\n",
    "- Also, try tuning more hyperparameters like `max_features` to find a more optimal version of the model \n",
    "- Or - try different model types! <<"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "lr = LinearRegression()\n",
    "lr.fit(x_train, y_train)\n",
    "y_pred_lr = lr.predict(x_test)\n",
    "\n",
    "score = performance(y_test, y_pred_lr)\n",
    "score[0], score[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestRegressor(max_depth=7, min_samples_split=4, random_state=123)\n",
    "\n",
    "rf.fit(x_train, y_train)\n",
    "y_pred_rf = rf.predict(x_test)\n",
    "\n",
    "score = performance(y_test, y_pred_rf)\n",
    "score[0], score[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here # Identify the optimal tree depth for given data\n",
    "max_depths = np.linspace(1, 30, 30, endpoint=True)\n",
    "mse_results = []\n",
    "r2_results = []\n",
    "\n",
    "for max_depth in max_depths:\n",
    "    regressor = RandomForestRegressor(max_depth=max_depth, \n",
    "                                      random_state=45)\n",
    "    regressor.fit(x_train, y_train)\n",
    "    y_pred = regressor.predict(x_test)\n",
    "    score = performance(y_test, y_pred)\n",
    "    r2_results.append(score[0])\n",
    "    mse_results.append(score[1])\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(max_depths, r2_results, 'b', label='R2')\n",
    "plt.xlabel('Tree Depth')\n",
    "plt.ylabel('R-squared')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(max_depths, mse_results, 'r', label='RMSE')\n",
    "plt.xlabel('Tree Depth')\n",
    "plt.ylabel('RMSE')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify the optimal minimum split size for given data\n",
    "min_samples_splits = np.arange(5, 26)\n",
    "mse_results = []\n",
    "r2_results = []\n",
    "\n",
    "for min_samples_split in min_samples_splits:\n",
    "    regressor = RandomForestRegressor(min_samples_split=int(min_samples_split),\n",
    "                                      random_state=123)\n",
    "    regressor.fit(x_train, y_train)\n",
    "    y_pred = regressor.predict(x_test)\n",
    "    score = performance(y_test, y_pred)\n",
    "    r2_results.append(score[0])\n",
    "    mse_results.append(score[1])\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(min_samples_splits, r2_results, 'b', label='R2')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(min_samples_splits, mse_results, 'r', label='RMSE')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_final = RandomForestRegressor(max_depth=7, min_samples_split=18, random_state=123)\n",
    "\n",
    "rf_final.fit(x_train, y_train)\n",
    "y_pred_final = rf_final.predict(x_test)\n",
    "\n",
    "score = performance(y_test, y_pred_final)\n",
    "score[0], score[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not great - but not terrible. Let's deploy it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pickle the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "pickle.dump(rf_final, open('model.sav', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model = pickle.load(open('model.sav', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Testing for Streamlit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "x_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = pd.DataFrame(columns = x_train.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = test_data.append({'LotArea': 1300, '1stFlrSF' : 350, 'GrLivArea': 350}, \n",
    "                             ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model.predict(test_data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
